import json, os, re
import pandas as pd
import openai
from sklearn.metrics import precision_score, recall_score, f1_score
from utils import load_sentences

def prepare_conll_dataframe(conll_data):
    rows = []
    for i, sentence in enumerate(conll_data):
        for word, label in sentence:
            rows.append({"Sentence_ID": i, "Entity": word, "Label": label})
    return pd.DataFrame(rows)

def ner_llama(sentences, model, api_key, save_dir="ner_results", batch_id=0):
    os.makedirs(save_dir, exist_ok=True)
    openai.api_key = api_key
    openai.api_base = "https://api.together.xyz/v1"

    prompt = f"""You've got a task.

    Find all named entities in the following sentence using the BIO tagging format:

    - Allowed labels: "B-LOC", "B-MISC", "B-ORG", "B-PER", "I-LOC", "I-MISC", "I-ORG", "I-PER", "O".
    - Where:
      - B- = beginning of an entity
      - I- = inside an entity
      - O = outside any entity
    - Entity types:
      - PERS — person
      - LOC — location
      - ORG — organization
      - MISC — miscellaneous
    For example George Bush would be tagged like that: George (B-PER) Bush (I-PER) - single word per entity strictly.

    Notice that you should label not only entites, you should use 'O' label for words that are not named entities (they can be any part of speech: verbs, prepositions) and include them please in your output.
    Also it is very important that sentences that starts with different numbers are separated. To remember it, include the number of sentence in the output.

    Example of an output:
    Sentence 1: EU rejects German call to boycott British lamb;
    Entities: ('EU', 'B-ORG') ('rejects', 'O') ('German', 'B-MISC') ('call', 'O') ('to', 'O') ('boycott', 'O') ('British', 'B-MISC') ('lamb', 'O') ('.', 'O').

    Sentence: "{sentences}"
    """

    for i, sentence in enumerate(sentences, 1):
        prompt += f"{i}. {sentence}\n"
    prompt += "\nAnswer:\n"

    response = openai.ChatCompletion.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
        max_tokens=2048
    )

    output = response["choices"][0]["message"]["content"]
    filename = os.path.join(save_dir, f"batch_{batch_id}.json")
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    return output

def parse_llm_outputs(folder_path):
    texts, entity_dict = [], {}
    counter = 1
    pattern = r"Entities: ((?:\('.*?', '.*?'\) ?)+)"

    for fname in os.listdir(folder_path):
        if fname.endswith('.json'):
            with open(os.path.join(folder_path, fname), 'r', encoding='utf-8') as f:
                text = json.dumps(json.load(f), ensure_ascii=False)
                matches = re.findall(pattern, text)
                for entities_raw in matches:
                    entities = re.findall(r"\('(.*?)', '(.*?)'\)", entities_raw)
                    entity_dict[counter] = entities
                    counter += 1
    rows = []
    for sid, ents in entity_dict.items():
        for entity, label in ents:
            rows.append({'Sentence_id': sid, 'Entity': entity, 'Label': label})
    df = pd.DataFrame(rows)
    allowed = ['B-LOC','B-MISC','B-ORG','B-PER','I-LOC','I-MISC','I-ORG','I-PER','O']
    return df[df["Label"].isin(allowed)]

def run_ner_experiment(config_path="config.json"):
    with open(config_path, "r") as f:
        config = json.load(f)

    # 1. Load CoNLL data
    conll_train = load_sentences(config["train_path"])
    conll_test = load_sentences(config["test_path"])
    df_conll = prepare_conll_dataframe(conll_train + conll_test)

    # 2. Prepare sentences
    sentences = df_conll.groupby('Sentence_ID')['Entity'].apply(lambda x: ' '.join(x)).tolist()
    sentences = list(enumerate(sentences, start=1))

    # 3. Run LLM NER
    for i in range(0, len(sentences), config["batch_size"]):
        batch = sentences[i:i+config["batch_size"]]
        ner_llama(
            [s[1] for s in batch],
            model=config["llm_model"],
            api_key=config["api_key"],
            save_dir=config["save_dir"],
            batch_id=i // config["batch_size"]
        )

    # 4. Parse LLM output
    df_llm = parse_llm_outputs(config["json_folder"])
    df_llm = df_llm.rename(columns={"Sentence_id": "Sentence_ID", "Label": "Label_LLM"})

    # 5. Merge and evaluate
    merged = pd.merge(df_conll, df_llm, on=["Sentence_ID", "Entity"], how="inner")
    print("Precision:", precision_score(merged["Label"], merged["Label_LLM"], average="weighted"))
    print("Recall:", recall_score(merged["Label"], merged["Label_LLM"], average="weighted"))
    print("F1 Score:", f1_score(merged["Label"], merged["Label_LLM"], average="weighted"))
